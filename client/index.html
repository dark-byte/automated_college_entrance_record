<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OCR Camera Capture</title>
</head>
<body>
    <h1>OCR Camera Capture</h1>

    <video id="cameraFeed" width="640" height="480" autoplay></video>
    <button id="captureButton">Capture Photo</button>
    <canvas id="capturedCanvas" width="640" height="480"></canvas>
    <button id="performOCRButton">Perform OCR</button>
    <div id="recognizedText"></div>

    <script src="https://cdn.jsdelivr.net/npm/tesseract.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const cameraFeed = document.getElementById('cameraFeed');
            const captureButton = document.getElementById('captureButton');
            const capturedCanvas = document.getElementById('capturedCanvas');
            const performOCRButton = document.getElementById('performOCRButton');
            const recognizedText = document.getElementById('recognizedText');

            let stream;
            let imageCapture;

            // Access the camera and set up video feed
            navigator.mediaDevices.getUserMedia({ video: true })
                .then((mediaStream) => {
                    stream = mediaStream;
                    cameraFeed.srcObject = mediaStream;

                    const track = mediaStream.getVideoTracks()[0];
                    imageCapture = new ImageCapture(track);
                })
                .catch((error) => {
                    console.error('Error accessing camera:', error);
                });

            // Capture photo from the camera feed
            captureButton.addEventListener('click', () => {
                const context = capturedCanvas.getContext('2d');
                context.drawImage(cameraFeed, 0, 0, capturedCanvas.width, capturedCanvas.height);
            });

            // Perform OCR on the captured image
            performOCRButton.addEventListener('click', () => {
                const imageData = capturedCanvas.toDataURL('image/png');
                const imageBlob = dataURItoBlob(imageData);

                Tesseract.recognize(
                    imageBlob,
                    'eng',
                    { logger: info => console.log(info) }
                )
                    .then(({ data: { text } }) => {
                        recognizedText.innerText = 'Recognized text: ' + text;
                    })
                    .catch(error => {
                        console.error('Error:', error);
                    });
            });

            // Convert data URI to Blob
            function dataURItoBlob(dataURI) {
                const byteString = atob(dataURI.split(',')[1]);
                const mimeString = dataURI.split(',')[0].split(':')[1].split(';')[0];
                const ab = new ArrayBuffer(byteString.length);
                const ia = new Uint8Array(ab);
                for (let i = 0; i < byteString.length; i++) {
                    ia[i] = byteString.charCodeAt(i);
                }
                return new Blob([ab], { type: mimeString });
            }

            // Clean up when the page is closed
            window.addEventListener('beforeunload', () => {
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
            });
        });
    </script>
</body>
</html>
